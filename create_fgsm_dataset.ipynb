{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777a371f-2402-4116-9429-c9056f73ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torch\n",
    "import accelerate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-small-imagenet1k-1-layer\", token=HF_TOKEN)\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    \"facebook/dinov2-small-imagenet1k-1-layer\",\n",
    "    dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ddf7a4-6dd9-4396-a6d6-79226f4dcb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Using GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available! Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21721196-c9f8-4882-a5c7-6c6cedf99c94",
   "metadata": {},
   "source": [
    "# Generate the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f81da64-c916-4b53-8b0a-5a2a8566e716",
   "metadata": {},
   "source": [
    "Note that we run FGSM with $\\epsilon = 0.1, 0.3, 0.5$ to measure various perturbation strengths. Also, we *only* consider images that were correctly classified initially; otherwise, our FGSM attack is kind of useless and wastes memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82359208-a9d3-4a64-95e0-dbdbc92b59d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7391836bcd49069ee67005bc691f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing & Uploading:   0%|          | 0/100000 [00:00<?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a28aa60dbab4fe8a1a103aa8a455ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c718ba80fcf4571b4a8ab2043a70617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef1278539c449b791c3721ad05ea19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0408bfa86bf847b89b8c739f1615fb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1d3f3760024ea7a34e7bb78425212a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003a2038bde54a3b8209c2d3caf80a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import Dataset, load_dataset, concatenate_datasets\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from huggingface_hub import HfApi, login, create_repo\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "from image_processing import tensor_to_pil\n",
    "from model_utils import generate_loss, get_classification, fgsm_attack\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# Suppress warnings and unnecessary output\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '1'\n",
    "disable_progress_bar()  # Disable datasets progress bars\n",
    "\n",
    "# Suppress datasets logging\n",
    "logging.getLogger(\"datasets\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def process_and_upload_sharded(\n",
    "    repo_id=\"areebg9/perturbed-imagenet-fgsm\",\n",
    "    total_samples=100000,\n",
    "    batch_size=100,\n",
    "    shard_size=1000,\n",
    "    epsilons=[0.1, 0.3, 0.5],\n",
    "    token=None,\n",
    "    skip_misclassified=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Process and upload as separate shards (parquet files) - much more efficient!\n",
    "    \"\"\"\n",
    "    if token is None:\n",
    "        token = os.getenv(\"HF_TOKEN\")\n",
    "    \n",
    "    login(token=token)\n",
    "    \n",
    "    # Create repo\n",
    "    api = HfApi(token=token)\n",
    "    try:\n",
    "        create_repo(repo_id, repo_type=\"dataset\", private=True)\n",
    "    except:\n",
    "        pass  # Repo already exists\n",
    "    \n",
    "    ds = load_dataset(\n",
    "        \"ILSVRC/imagenet-1k\", \n",
    "        split=\"train\", \n",
    "        streaming=True,\n",
    "        token=token\n",
    "    )\n",
    "    \n",
    "    ds_iter = iter(ds)\n",
    "    samples_processed = 0\n",
    "    samples_skipped = 0\n",
    "    samples_used = 0\n",
    "    batch_datasets = []\n",
    "    shard_count = 0\n",
    "    \n",
    "    num_batches = (total_samples + batch_size - 1) // batch_size\n",
    "    \n",
    "    # Single consolidated progress bar\n",
    "    pbar = tqdm(total=total_samples, desc=\"Processing & Uploading\", \n",
    "                bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {postfix}')\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        batch_data = []\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            if samples_processed >= total_samples:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                sample = next(ds_iter)\n",
    "                batch_images.append(sample['image'])\n",
    "                batch_labels.append(sample['label'])\n",
    "                samples_processed += 1\n",
    "            except StopIteration:\n",
    "                break\n",
    "        \n",
    "        if len(batch_images) == 0:\n",
    "            break\n",
    "        \n",
    "        for i in range(len(batch_images)):\n",
    "            # Check if original prediction is correct\n",
    "            try:\n",
    "                loss, inputs = generate_loss(model, batch_images[i], batch_labels[i], processor)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    original_label_name, original_pred_idx = get_classification(model, inputs)\n",
    "                \n",
    "                # Skip if originally misclassified\n",
    "                if skip_misclassified and batch_labels[i] != original_pred_idx:\n",
    "                    samples_skipped += 1\n",
    "                    pbar.set_postfix({\n",
    "                        'skipped': samples_skipped, \n",
    "                        'used': samples_used,\n",
    "                        'shards': shard_count\n",
    "                    })\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                samples_used += 1\n",
    "                \n",
    "                # Now generate perturbations for this correctly classified image\n",
    "                for epsilon in epsilons:\n",
    "                    try:\n",
    "                        # Regenerate loss for each epsilon (gradients are consumed)\n",
    "                        loss, inputs = generate_loss(model, batch_images[i], batch_labels[i], processor)\n",
    "                        perturbed_input = fgsm_attack(inputs, loss, epsilon)\n",
    "                        perturbed_pil = tensor_to_pil(perturbed_input['pixel_values'][0], processor)\n",
    "                        \n",
    "                        with torch.no_grad():\n",
    "                            perturbed_label_name, perturbed_pred_idx = get_classification(model, perturbed_input)\n",
    "                        \n",
    "                        batch_data.append({\n",
    "                            'image': perturbed_pil,\n",
    "                            'original_image_index': samples_processed - len(batch_images) + i,\n",
    "                            'attack_type': 'FGSM',\n",
    "                            'epsilon': epsilon,\n",
    "                            'original_label': batch_labels[i],\n",
    "                            'original_label_name': original_label_name,\n",
    "                            'original_prediction_idx': original_pred_idx,\n",
    "                            'original_prediction_name': original_label_name,\n",
    "                            'perturbed_prediction_idx': perturbed_pred_idx,\n",
    "                            'perturbed_prediction_name': perturbed_label_name,\n",
    "                            'successful_attack': original_pred_idx != perturbed_pred_idx\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    'skipped': samples_skipped, \n",
    "                    'used': samples_used,\n",
    "                    'shards': shard_count\n",
    "                })\n",
    "                pbar.update(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "        \n",
    "        if batch_data:\n",
    "            batch_dataset = Dataset.from_dict({\n",
    "                'image': [item['image'] for item in batch_data],\n",
    "                'original_image_index': [item['original_image_index'] for item in batch_data],\n",
    "                'attack_type': [item['attack_type'] for item in batch_data],\n",
    "                'epsilon': [item['epsilon'] for item in batch_data],\n",
    "                'original_label': [item['original_label'] for item in batch_data],\n",
    "                'original_label_name': [item['original_label_name'] for item in batch_data],\n",
    "                'original_prediction_idx': [item['original_prediction_idx'] for item in batch_data],\n",
    "                'original_prediction_name': [item['original_prediction_name'] for item in batch_data],\n",
    "                'perturbed_prediction_idx': [item['perturbed_prediction_idx'] for item in batch_data],\n",
    "                'perturbed_prediction_name': [item['perturbed_prediction_name'] for item in batch_data],\n",
    "                'successful_attack': [item['successful_attack'] for item in batch_data],\n",
    "            })\n",
    "            batch_datasets.append(batch_dataset)\n",
    "        \n",
    "        del batch_images, batch_labels, batch_data\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Upload shard when we have enough data\n",
    "        samples_in_buffer = sum(len(d) for d in batch_datasets)\n",
    "        if samples_in_buffer >= shard_size * len(epsilons) or samples_processed >= total_samples:\n",
    "            if batch_datasets:\n",
    "                shard_dataset = concatenate_datasets(batch_datasets)\n",
    "                \n",
    "                # Upload as parquet shard (quietly)\n",
    "                shard_dataset.to_parquet(f\"temp_shard_{shard_count}.parquet\")\n",
    "                api.upload_file(\n",
    "                    path_or_fileobj=f\"temp_shard_{shard_count}.parquet\",\n",
    "                    path_in_repo=f\"data/train-{shard_count:05d}-of-{total_samples//shard_size:05d}.parquet\",\n",
    "                    repo_id=repo_id,\n",
    "                    repo_type=\"dataset\",\n",
    "                    token=token\n",
    "                )\n",
    "                \n",
    "                # Delete local file\n",
    "                os.remove(f\"temp_shard_{shard_count}.parquet\")\n",
    "                \n",
    "                shard_count += 1\n",
    "                pbar.set_postfix({\n",
    "                    'skipped': samples_skipped, \n",
    "                    'used': samples_used,\n",
    "                    'shards': shard_count\n",
    "                })\n",
    "                batch_datasets = []\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    print(\"Summary:\")\n",
    "    print(f\"Total samples processed: {samples_processed}\")\n",
    "    print(f\"Samples skipped (misclassified): {samples_skipped}\")\n",
    "    print(f\"Samples used (correctly classified): {samples_used}\")\n",
    "    print(f\"Total shards uploaded: {shard_count}\")\n",
    "    print(f\"Total perturbed images: {samples_used * len(epsilons)}\")\n",
    "\n",
    "\n",
    "process_and_upload_sharded(\n",
    "    repo_id=\"areebg9/perturbed-imagenet-fgsm\",\n",
    "    total_samples=100000,\n",
    "    batch_size=100,\n",
    "    shard_size=1000,\n",
    "    epsilons=[0.1, 0.3, 0.5],\n",
    "    token=HF_TOKEN,\n",
    "    skip_misclassified=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
